{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "# Fungsi untuk memuat model yang sudah dilatih\n",
    "def load_model(model, load_model_name=\"model\", load_model_dir=\"E:/code/project-list/bert-hfacs/models/model_trained/\"):\n",
    "    # Pastikan direktori ada, jika tidak buat\n",
    "    os.makedirs(load_model_dir, exist_ok=True)\n",
    "\n",
    "    # Gabungkan nama model dengan ekstensi .pth\n",
    "    load_model_name_with_extension = load_model_name + \".pth\"\n",
    "\n",
    "    # Gabungkan direktori dan nama file model\n",
    "    load_path = os.path.join(load_model_dir, load_model_name_with_extension)\n",
    "\n",
    "    # Memuat model state_dict\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            load_path,\n",
    "            map_location=torch.device('cpu'),  # Ganti ke 'cuda' jika menggunakan GPU\n",
    "        )\n",
    "    )\n",
    "    print(\"Model Weight Loaded\")\n",
    "    return model\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Seed for CUDA\n",
    "set_seed(1)\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load tokenizer dan model IndoBERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"E:/code/project-list/bert-hfacs/models/indobert_base\")\n",
    "model = BertModel.from_pretrained(\"E:/code/project-list/bert-hfacs/models/indobert_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Buat config dengan arsitektur paling sederhana\n",
    "config = BertConfig(\n",
    "    hidden_size=4,  # Ukuran hidden layer, harus sama denan intermediate size\n",
    "    num_attention_heads=1,  # 1 attention head\n",
    "    num_hidden_layers=1,  # 1 layer\n",
    "    intermediate_size=4,  # Ukuran layer feed-forward (sederhana)\n",
    "    vocab_size=30522,  # Ukuran vocabulary standar BERT\n",
    "    max_position_embeddings=512,  # Ukuran input yang bisa diterima model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Contoh input teks\n",
    "input_text = \"supir mobil kantuk\"\n",
    "tokens = tokenizer(input_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] supir mobil kantuk [SEP]'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 4, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 4)\n",
      "    (token_type_embeddings): Embedding(2, 4)\n",
      "    (LayerNorm): LayerNorm((4,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): Linear(in_features=4, out_features=4, bias=True)\n",
      "            (key): Linear(in_features=4, out_features=4, bias=True)\n",
      "            (value): Linear(in_features=4, out_features=4, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=4, out_features=4, bias=True)\n",
      "            (LayerNorm): LayerNorm((4,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=4, out_features=4, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4, out_features=4, bias=True)\n",
      "          (LayerNorm): LayerNorm((4,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 14884,   895, 27395,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6163,  0.9201,  1.1345, -0.4383],\n",
       "         [-1.2845,  1.7137, -0.5747,  0.1455],\n",
       "         [-1.8702,  0.7533,  0.9117,  0.2052],\n",
       "         [-1.6609,  0.7850,  1.2060, -0.3302],\n",
       "         [ 0.5764, -0.0000,  1.5312, -1.1957]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = model.embeddings(tokens['input_ids'])\n",
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bobot awal Query (sebelum update): Parameter containing:\n",
      "tensor([[-0.0271,  0.0188, -0.0045, -0.0036],\n",
      "        [ 0.0110,  0.0145, -0.0327,  0.0227],\n",
      "        [-0.0190,  0.0167,  0.0314, -0.0204],\n",
      "        [ 0.0054, -0.0004, -0.0021, -0.0029]], requires_grad=True)\n",
      "Bobot awal Key (sebelum update): Parameter containing:\n",
      "tensor([[ 0.0063,  0.0292,  0.0430, -0.0197],\n",
      "        [ 0.0190,  0.0304,  0.0208, -0.0135],\n",
      "        [ 0.0076, -0.0022,  0.0024,  0.0209],\n",
      "        [-0.0273,  0.0289,  0.0046, -0.0183]], requires_grad=True)\n",
      "Bobot awal Value (sebelum update): Parameter containing:\n",
      "tensor([[-0.0131,  0.0152, -0.0041, -0.0043],\n",
      "        [-0.0060, -0.0177, -0.0194, -0.0141],\n",
      "        [ 0.0275, -0.0086, -0.0065, -0.0487],\n",
      "        [ 0.0359, -0.0056,  0.0079,  0.0053]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 4. Mengakses bobot Q, K, V pada layer pertama dan mencetak bobot awal sebelum update\n",
    "layer_index = 0\n",
    "query_weights = model.encoder.layer[layer_index].attention.self.query.weight\n",
    "key_weights = model.encoder.layer[layer_index].attention.self.key.weight\n",
    "value_weights = model.encoder.layer[layer_index].attention.self.value.weight\n",
    "\n",
    "print(\"Bobot awal Query (sebelum update):\", query_weights)\n",
    "print(\"Bobot awal Key (sebelum update):\", key_weights)\n",
    "print(\"Bobot awal Value (sebelum update):\", value_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bias = model.encoder.layer[layer_index].attention.self.query.bias\n",
    "key_bias = model.encoder.layer[layer_index].attention.self.key.bias\n",
    "value_bias = model.encoder.layer[layer_index].attention.self.value.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bobot awal Query (sebelum update): Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "Bobot awal Key (sebelum update): Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "Bobot awal Value (sebelum update): Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Bobot awal Query (sebelum update):\", query_bias)\n",
    "print(\"Bobot awal Key (sebelum update):\", key_bias)\n",
    "print(\"Bobot awal Value (sebelum update):\", value_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "print(query_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Menghitung nilai Q, K, V untuk setiap kata dalam input embeddings\n",
    "query = torch.matmul(input_embeddings, query_weights.T)\n",
    "key = torch.matmul(input_embeddings, key_weights.T)\n",
    "value = torch.matmul(input_embeddings, value_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai value: tensor([[[ 0.0576, -0.0515,  0.0906, -0.0103],\n",
      "         [ 0.0692,  0.0329,  0.0319, -0.0069],\n",
      "         [ 0.0601, -0.0348,  0.0725, -0.0130],\n",
      "         [ 0.0556, -0.0538,  0.0892, -0.0109],\n",
      "         [-0.0182, -0.0709,  0.0616,  0.0034]]], grad_fn=<UnsafeViewBackward0>)\n",
      "Nilai value: tensor([[[ 0.0741,  0.0267, -0.0207,  0.0841],\n",
      "         [ 0.0143,  0.0137, -0.0118,  0.0794],\n",
      "         [ 0.0454,  0.0035, -0.0093,  0.0734],\n",
      "         [ 0.0708,  0.0218, -0.0183,  0.0798],\n",
      "         [ 0.0931,  0.0589, -0.0169,  0.0132]]], grad_fn=<UnsafeViewBackward0>)\n",
      "Nilai value: tensor([[[ 0.0324, -0.0223, -0.0384, -0.0566],\n",
      "         [ 0.0447, -0.0134, -0.0534, -0.0595],\n",
      "         [ 0.0314, -0.0226, -0.0738, -0.0631],\n",
      "         [ 0.0302, -0.0226, -0.0442, -0.0563],\n",
      "         [-0.0088, -0.0163,  0.0641,  0.0265]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Nilai value:\", query)\n",
    "print(\"Nilai value:\", key)\n",
    "print(\"Nilai value:\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Menghitung skor attention antara setiap pasangan kata\n",
    "d_k = query.size(-1)\n",
    "attention_scores = torch.matmul(query, key.transpose(-1, -2)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "tensor([[[ 7.9609e-05, -8.8093e-04,  4.1720e-04,  2.4197e-04,  3.3015e-04],\n",
      "         [ 2.3832e-03,  2.6061e-04,  1.2257e-03,  2.2419e-03,  3.8722e-03],\n",
      "         [ 4.6556e-04, -7.4992e-04,  4.8663e-04,  5.6720e-04,  1.0701e-03],\n",
      "         [-4.0757e-05, -9.2945e-04,  3.4909e-04,  1.3050e-04,  1.7330e-04],\n",
      "         [-2.1183e-03, -8.4624e-04, -7.0224e-04, -1.8478e-03, -3.4384e-03]]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(d_k)\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Normalisasi softmax pada skor attention \n",
    "attention_probs = F.softmax(attention_scores, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2000, 0.1998, 0.2001, 0.2000, 0.2001],\n",
      "         [0.2001, 0.1997, 0.1998, 0.2000, 0.2004],\n",
      "         [0.2000, 0.1998, 0.2000, 0.2000, 0.2001],\n",
      "         [0.2000, 0.1998, 0.2001, 0.2000, 0.2000],\n",
      "         [0.1999, 0.2002, 0.2002, 0.2000, 0.1997]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(attention_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Hitung representasi konteksual untuk setiap kata berdasarkan attention weights\n",
    "self_attention = torch.matmul(attention_probs, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0260, -0.0195, -0.0291, -0.0418],\n",
      "         [ 0.0260, -0.0194, -0.0291, -0.0418],\n",
      "         [ 0.0260, -0.0195, -0.0291, -0.0418],\n",
      "         [ 0.0260, -0.0195, -0.0291, -0.0418],\n",
      "         [ 0.0260, -0.0194, -0.0292, -0.0418]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(self_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0017,  0.0011, -0.0017, -0.0001],\n",
      "         [ 0.0017,  0.0011, -0.0017, -0.0001],\n",
      "         [ 0.0017,  0.0011, -0.0017, -0.0001],\n",
      "         [ 0.0017,  0.0011, -0.0017, -0.0001],\n",
      "         [ 0.0017,  0.0012, -0.0017, -0.0001]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 9. Feed-forward processing dalam layer encoder (berulang sesuai layer model IndoBERT)\n",
    "layer_output = model.encoder.layer[layer_index].output.dense(self_attention)\n",
    "print(layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Output Weights: Parameter containing:\n",
      "tensor([[-0.0343, -0.0583, -0.0181, -0.0213],\n",
      "        [-0.0288,  0.0012, -0.0244, -0.0290],\n",
      "        [-0.0044, -0.0004,  0.0199,  0.0236],\n",
      "        [ 0.0125, -0.0260,  0.0119,  0.0142]], requires_grad=True)\n",
      "Layer Output Bias: Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "layer_index = 0  # Contoh untuk layer pertama\n",
    "layer_output_weights = model.encoder.layer[layer_index].output.dense.weight\n",
    "layer_output_bias = model.encoder.layer[layer_index].output.dense.bias\n",
    "\n",
    "print(\"Layer Output Weights:\", layer_output_weights)\n",
    "print(\"Layer Output Bias:\", layer_output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Mengambil representasi dari token [CLS] untuk klasifikasi\n",
    "cls_representation = model.pooler.dense(layer_output[:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Layer klasifikasi sederhana dengan 2 kelas\n",
    "classification_layer = nn.Linear(model.config.hidden_size, 2)\n",
    "logits = classification_layer(cls_representation)\n",
    "predictions = torch.argmax(logits, dim=-1)  # Mengambil prediksi kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Layer Weights: Parameter containing:\n",
      "tensor([[ 0.2441,  0.0687,  0.4924,  0.0422],\n",
      "        [-0.1222,  0.1192,  0.4068, -0.3231]], requires_grad=True)\n",
      "Classification Layer Bias: Parameter containing:\n",
      "tensor([0.1400, 0.2900], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "classification_weights = classification_layer.weight\n",
    "classification_bias = classification_layer.bias\n",
    "\n",
    "print(\"Classification Layer Weights:\", classification_weights)\n",
    "print(\"Classification Layer Bias:\", classification_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1400, 0.2901]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Definisikan label target untuk contoh ini\n",
    "labels = torch.tensor([1])  # Misalnya label kelas positif, karena mengantuk termasuk PRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Hitung loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Optimizer (misalnya Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Backward pass untuk menghitung gradien\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Logging Gradient\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"Gradien {name}: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bobot Query sebelum update: tensor([[-0.0271,  0.0188, -0.0045, -0.0036],\n",
      "        [ 0.0110,  0.0145, -0.0327,  0.0227],\n",
      "        [-0.0190,  0.0167,  0.0314, -0.0204],\n",
      "        [ 0.0054, -0.0004, -0.0021, -0.0029]])\n",
      "Bobot Key sebelum update: tensor([[ 0.0063,  0.0292,  0.0430, -0.0197],\n",
      "        [ 0.0190,  0.0304,  0.0208, -0.0135],\n",
      "        [ 0.0076, -0.0022,  0.0024,  0.0209],\n",
      "        [-0.0273,  0.0289,  0.0046, -0.0183]])\n",
      "Bobot Value sebelum update: tensor([[-0.0131,  0.0152, -0.0041, -0.0043],\n",
      "        [-0.0060, -0.0177, -0.0194, -0.0141],\n",
      "        [ 0.0275, -0.0086, -0.0065, -0.0487],\n",
      "        [ 0.0359, -0.0056,  0.0079,  0.0053]])\n"
     ]
    }
   ],
   "source": [
    "# 16. Logging bobot Q, K, V sebelum update\n",
    "for name, param in model.named_parameters():\n",
    "    if \"encoder.layer.0.attention.self.query.weight\" in name:\n",
    "        print(\"Bobot Query sebelum update:\", param.data)\n",
    "    if \"encoder.layer.0.attention.self.key.weight\" in name:\n",
    "        print(\"Bobot Key sebelum update:\", param.data)\n",
    "    if \"encoder.layer.0.attention.self.value.weight\" in name:\n",
    "        print(\"Bobot Value sebelum update:\", param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Update bobot\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bobot Query setelah update: tensor([[-0.1215,  0.1093,  0.0876, -0.0855],\n",
      "        [-0.0830,  0.1043,  0.0589, -0.0581],\n",
      "        [ 0.0393, -0.0276, -0.0181,  0.0071],\n",
      "        [ 0.1009, -0.0928, -0.0958,  0.0823]])\n",
      "Bobot Key setelah update: tensor([[ 0.1026, -0.0635,  0.1353, -0.1132],\n",
      "        [-0.0768,  0.1223, -0.0706,  0.0794],\n",
      "        [ 0.1052, -0.0974,  0.0973, -0.0749],\n",
      "        [-0.1096,  0.0983, -0.0634,  0.0538]])\n",
      "Bobot Value setelah update: tensor([[-0.1131,  0.1152,  0.0959, -0.1042],\n",
      "        [ 0.0940, -0.1177, -0.1194,  0.0859],\n",
      "        [-0.0725,  0.0914,  0.0935, -0.1487],\n",
      "        [-0.0641,  0.0944,  0.1079, -0.0947]])\n"
     ]
    }
   ],
   "source": [
    "# 18. Logging bobot Q, K, V setelah update\n",
    "for name, param in model.named_parameters():\n",
    "    if \"encoder.layer.0.attention.self.query.weight\" in name:\n",
    "        print(\"Bobot Query setelah update:\", param.data)\n",
    "    if \"encoder.layer.0.attention.self.key.weight\" in name:\n",
    "        print(\"Bobot Key setelah update:\", param.data)\n",
    "    if \"encoder.layer.0.attention.self.value.weight\" in name:\n",
    "        print(\"Bobot Value setelah update:\", param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Layer Output Weights: Parameter containing:\n",
      "tensor([[ 0.0657, -0.1583, -0.1181, -0.1213],\n",
      "        [-0.1288,  0.1012,  0.0756,  0.0710],\n",
      "        [-0.1040,  0.0992,  0.1196,  0.1234],\n",
      "        [ 0.1125, -0.1260, -0.0881, -0.0858]], requires_grad=True)\n",
      "Updated Layer Output Bias: Parameter containing:\n",
      "tensor([ 0.1000, -0.1000, -0.1000,  0.1000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "layer_index = 0 \n",
    "updated_layer_output_weights = model.encoder.layer[layer_index].output.dense.weight\n",
    "updated_layer_output_bias = model.encoder.layer[layer_index].output.dense.bias\n",
    "\n",
    "print(\"Updated Layer Output Weights:\", updated_layer_output_weights)\n",
    "print(\"Updated Layer Output Bias:\", updated_layer_output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Classification Layer Weights: Parameter containing:\n",
      "tensor([[ 0.2441,  0.0687,  0.4924,  0.0422],\n",
      "        [-0.1222,  0.1192,  0.4068, -0.3231]], requires_grad=True)\n",
      "Updated Classification Layer Bias: Parameter containing:\n",
      "tensor([0.1400, 0.2900], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "updated_classification_weights = classification_layer.weight\n",
    "updated_classification_bias = classification_layer.bias\n",
    "\n",
    "print(\"Updated Classification Layer Weights:\", updated_classification_weights)\n",
    "print(\"Updated Classification Layer Bias:\", updated_classification_bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
